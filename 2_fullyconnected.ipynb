{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 2\n",
    "------------\n",
    "\n",
    "Previously in `1_notmnist.ipynb`, we created a pickle with formatted datasets for training, development and testing on the [notMNIST dataset](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html).\n",
    "\n",
    "The goal of this assignment is to progressively train deeper and more accurate models using TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in `1_notmnist.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 19456,
     "status": "ok",
     "timestamp": 1449847956073,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "0ddb1607-1fc4-4ddb-de28-6c7ab7fb0c33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "mainRoot = '/home/christophe/data/'\n",
    "mainRoot = ''\n",
    "\n",
    "pickle_file = mainRoot + 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 19723,
     "status": "ok",
     "timestamp": 1449847956364,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "2ba0fc75-1487-4ace-a562-cf81cae82793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nCLVqyQ5vPPH"
   },
   "source": [
    "We're first going to train a multinomial logistic regression using simple gradient descent.\n",
    "\n",
    "TensorFlow works like this:\n",
    "* First you describe the computation that you want to see performed: what the inputs, the variables, and the operations look like. These get created as nodes over a computation graph. This description is all contained within the block below:\n",
    "\n",
    "      with graph.as_default():\n",
    "          ...\n",
    "\n",
    "* Then you can run the operations on this graph as many times as you want by calling `session.run()`, providing it outputs to fetch from the graph that get returned. This runtime operation is all contained in the block below:\n",
    "\n",
    "      with tf.Session(graph=graph) as session:\n",
    "          ...\n",
    "\n",
    "Let's load all the data into TensorFlow and build the computation graph corresponding to our training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Nfv39qvtvOl_"
   },
   "outputs": [],
   "source": [
    "# With gradient descent training, even this much data is prohibitive.\n",
    "# Subset the training data for faster turnaround.\n",
    "train_subset = 10000\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    # Load the training, validation and test data into constants that are attached to the graph.\n",
    "    tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "    tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    # These are the parameters that we are going to be training. The weight\n",
    "    # matrix will be initialized using random valued following a (truncated)\n",
    "    # normal distribution. The biases get initialized to zero.\n",
    "    weights = tf.Variable( tf.truncated_normal([image_size * image_size, num_labels]) )\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    # We multiply the inputs with the weight matrix, and add biases. We compute\n",
    "    # the softmax and cross-entropy (it's one operation in TensorFlow, because\n",
    "    # it's very common, and it can be optimized). We take the average of this\n",
    "    # cross-entropy across all training examples: that's our loss.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels) )\n",
    "\n",
    "    # Optimizer.\n",
    "    # We are going to find the minimum of this loss using gradient descent.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    # These are not part of training, but merely here so that we can report accuracy figures as we train.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax( tf.matmul(tf_valid_dataset, weights) + biases )\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KQcL4uqISHjP"
   },
   "source": [
    "Let's run this computation and iterate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 9
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 57454,
     "status": "ok",
     "timestamp": 1449847994134,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "z2cjdenH869W",
    "outputId": "4c037ba1-b526-4d8e-e632-91e2a0333267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 17.805939\n",
      "Training accuracy: 9.8%\n",
      "Validation accuracy: 12.1%\n",
      "Loss at step 100: 2.372797\n",
      "Training accuracy: 71.6%\n",
      "Validation accuracy: 70.2%\n",
      "Loss at step 200: 1.891438\n",
      "Training accuracy: 74.6%\n",
      "Validation accuracy: 72.7%\n",
      "Loss at step 300: 1.633296\n",
      "Training accuracy: 76.2%\n",
      "Validation accuracy: 73.5%\n",
      "Loss at step 400: 1.461550\n",
      "Training accuracy: 77.0%\n",
      "Validation accuracy: 74.0%\n",
      "Loss at step 500: 1.336605\n",
      "Training accuracy: 77.7%\n",
      "Validation accuracy: 74.4%\n",
      "Loss at step 600: 1.239794\n",
      "Training accuracy: 78.5%\n",
      "Validation accuracy: 74.6%\n",
      "Loss at step 700: 1.161579\n",
      "Training accuracy: 78.9%\n",
      "Validation accuracy: 74.9%\n",
      "Loss at step 800: 1.096591\n",
      "Training accuracy: 79.4%\n",
      "Validation accuracy: 75.1%\n",
      "Test accuracy: 82.8%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 801\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    # This is a one-time operation which ensures the parameters get initialized as\n",
    "    # we described in the graph: random weights for the matrix, zeros for the biases.\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # Run the computations. We tell .run() that we want to run the optimizer,\n",
    "        # and get the loss value and the training predictions returned as numpy arrays.\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "        if (step % 100 == 0):\n",
    "            print('Loss at step %d: %f' % (step, l))\n",
    "            print('Training accuracy: %.1f%%' % accuracy(predictions, train_labels[:train_subset, :]))\n",
    "            # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "            # just to get that one numpy array. Note that it recomputes all its graph dependencies.\n",
    "            print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x68f-hxRGm3H"
   },
   "source": [
    "Let's now switch to stochastic gradient descent training instead, which is much faster.\n",
    "\n",
    "The graph will be similar, except that instead of holding all the training data into a constant node, we create a `Placeholder` node which will be fed actual data at every call of `session.run()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "qhPMzWYRGrzM"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size)) # ONLY DIFF FOR SGD\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels)) # ONLY DIFF FOR SGD\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XmVZESmtG4JH"
   },
   "source": [
    "Let's run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 6
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 66292,
     "status": "ok",
     "timestamp": 1449848003013,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "FoF91pknG_YW",
    "outputId": "d255c80e-954d-4183-ca1c-c7333ce91d0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 15.640719\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 17.8%\n",
      "Minibatch loss at step 500: 1.576966\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 75.8%\n",
      "Minibatch loss at step 1000: 1.097162\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 1500: 1.065101\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 2000: 0.721755\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 2500: 1.380634\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 3000: 0.706102\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 79.3%\n",
      "Test accuracy: 86.1%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7omWxtvLLxik"
   },
   "source": [
    "---\n",
    "Problem\n",
    "-------\n",
    "\n",
    "Turn the logistic regression example with SGD into a 1-hidden layer neural network with rectified linear units [nn.relu()](https://www.tensorflow.org/versions/r0.7/api_docs/python/nn.html#relu) and 1024 hidden nodes. This model should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 383.427460\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 36.9%\n",
      "Minibatch loss at step 100: 36.899216\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 200: 30.036089\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 300: 26.471102\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 400: 10.459159\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 500: 13.934364\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 600: 13.913607\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 700: 12.483553\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 800: 10.838910\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 900: 18.767033\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 1000: 32.627804\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 1100: 7.553691\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1200: 13.541763\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 1300: 8.741716\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1400: 8.224554\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 1500: 7.329010\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 1600: 2.321066\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 1700: 6.149971\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 82.3%\n",
      "Minibatch loss at step 1800: 2.581779\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 82.7%\n",
      "Minibatch loss at step 1900: 6.062996\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 2000: 2.619470\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2100: 7.154984\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2200: 5.015959\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2300: 1.922543\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 2400: 1.857754\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 2500: 7.165487\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 2600: 4.332179\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2700: 5.444972\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2800: 4.942314\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 2900: 4.374789\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 3000: 2.398074\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 82.5%\n",
      "Test accuracy: 88.4%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEcCAYAAAAiOsTUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wDDdij2ucJ1jAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c10264f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "hidden_nodes = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size)) # ONLY DIFF FOR SGD\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels)) # ONLY DIFF FOR SGD\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    weights_1 = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_nodes]))\n",
    "    biases_1 = tf.Variable(tf.zeros([hidden_nodes]))\n",
    "    weights_2 = tf.Variable(tf.truncated_normal([hidden_nodes, num_labels]))\n",
    "    biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    def forward_prop(inp):\n",
    "        h1 = tf.nn.relu(tf.matmul(inp, weights_1) + biases_1)\n",
    "        return tf.matmul(h1,weights_2) + biases_2\n",
    "\n",
    "    # Training computation.\n",
    "    logits = forward_prop(tf_train_dataset)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(forward_prop(tf_valid_dataset))\n",
    "    test_prediction = tf.nn.softmax(forward_prop(tf_test_dataset))\n",
    "\n",
    "\n",
    "num_steps = 3001\n",
    "data = np.ndarray(shape=(1+num_steps//100,4), dtype=np.float32)\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 100 == 0):\n",
    "            batch_score = accuracy(predictions, batch_labels)\n",
    "            valid_score = accuracy(valid_prediction.eval(), valid_labels)\n",
    "            test_score = accuracy(test_prediction.eval(), test_labels)\n",
    "            data[step//100,:] = [step*batch_size, batch_score/100, valid_score/100, test_score/100]\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % batch_score)\n",
    "            print(\"Validation accuracy: %.1f%%\" % valid_score)\n",
    "    print(\"Test accuracy: %.1f%%\" % test_score)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(data[:,0], data[:,1:4])\n",
    "ax.set_title('Scores given training size')\n",
    "ax.legend(('batch','valid', 'test'), loc='lower right')\n",
    "ax.set_xticks(data[:,0])\n",
    "ax.set_xlabel('Training size')\n",
    "ax.set_ylim(0,1.01)\n",
    "ax.grid()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "2_fullyconnected.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
